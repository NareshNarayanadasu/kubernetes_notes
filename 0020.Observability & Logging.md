Excellent 🚀 Now we’re stepping into **Week 6 – Observability & Logging**, starting with **Day 36–37: Metrics with Prometheus & Grafana**.
This is critical because **“You can’t manage what you can’t measure”** — observability ensures we understand what’s happening inside the cluster.

I’ll cover **concepts → installation → hands-on lab → monitoring key metrics → visualization in Grafana → best practices → troubleshooting**.

---

# **Day 36–37: Metrics with Prometheus & Grafana**

---

## **1. Why Metrics Matter**

* Kubernetes clusters are **dynamic**: pods start, scale, move, and die frequently.
* Metrics help answer:

  * Is the cluster healthy?
  * Are pods over-consuming resources?
  * Is auto-scaling working properly?
  * Where are bottlenecks (CPU, memory, network, storage)?

👉 Prometheus is the **de facto monitoring tool** in Kubernetes.
👉 Grafana provides **beautiful dashboards** on top of Prometheus data.

---

## **2. Key Concepts**

### **Prometheus**

* Time-series database + monitoring system.
* Pulls metrics via HTTP endpoints (`/metrics`).
* Stores them in **time-series format** (`<metric_name>{labels}` → value over time).

### **Grafana**

* Visualization + dashboard tool.
* Connects to Prometheus as a **data source**.
* Provides alerts and pre-built Kubernetes dashboards.

---

## **3. Metrics Pipeline in Kubernetes**

1. **cAdvisor** (built into kubelet) → exposes per-container resource usage.
2. **kubelet** → exposes node & pod metrics.
3. **kube-state-metrics** → exposes cluster object states (Deployments, Pods, HPA).
4. **Prometheus** → scrapes all metrics.
5. **Grafana** → visualizes metrics.

---

## **4. Installing Prometheus & Grafana**

### Option 1: Using Helm (recommended)

```bash
# Add Helm repo
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Install Prometheus + Grafana stack
helm install kube-monitor prometheus-community/kube-prometheus-stack --namespace monitoring --create-namespace
```

👉 This installs:

* Prometheus
* Alertmanager
* Grafana
* Node Exporter
* Kube State Metrics

---

### Option 2: Using manifests

```bash
kubectl apply -f https://github.com/prometheus-operator/kube-prometheus/releases/download/v0.12.0/kube-prometheus-crds.yaml
kubectl apply -f https://github.com/prometheus-operator/kube-prometheus/releases/download/v0.12.0/kube-prometheus-manifests.yaml
```

---

## **5. Hands-On Lab**

### Step 1: Access Prometheus

```bash
kubectl port-forward svc/kube-monitor-prometheus 9090:9090 -n monitoring
```

👉 Open [http://localhost:9090](http://localhost:9090).
👉 Run sample query:

```
rate(container_cpu_usage_seconds_total[5m])
```

### Step 2: Access Grafana

```bash
kubectl port-forward svc/kube-monitor-grafana 3000:80 -n monitoring
```

👉 Open [http://localhost:3000](http://localhost:3000).

* Default login: `admin/prom-operator`.
* Import **Kubernetes dashboards** (ID: `315`, `6417`, `6416` on grafana.com).

---

## **6. Important Metrics to Monitor**

### **Cluster Level**

* `node_cpu_seconds_total` → CPU usage per node.
* `node_memory_MemAvailable_bytes` → free memory.
* `kube_node_status_condition{condition="Ready"}` → node health.

### **Pod Level**

* `container_cpu_usage_seconds_total` → per-container CPU.
* `container_memory_usage_bytes` → memory usage.
* `kube_pod_status_phase` → running/pending/crashloop.

### **App Level**

* `http_requests_total` → request count.
* `http_request_duration_seconds` → latency.

---

## **7. Example PromQL Queries**

* **CPU usage per pod (5m avg):**

```promql
rate(container_cpu_usage_seconds_total{namespace="default"}[5m])
```

* **Memory usage by pod:**

```promql
container_memory_usage_bytes{namespace="default"}
```

* **Pod restarts:**

```promql
kube_pod_container_status_restarts_total
```

---

## **8. Best Practices**

✅ Run Prometheus with **persistent storage** (PVC).
✅ Use **Grafana dashboards** per namespace/team.
✅ Set up **alerts** (e.g., CPU > 80% for 5m).
✅ Monitor **control plane components** (API server, etcd).
✅ Use **federated Prometheus** in large clusters.
✅ Limit retention (e.g., 15d) → otherwise disk fills up.

---

## **9. Troubleshooting**

* **Prometheus not scraping** → check `ServiceMonitor` or `Endpoints`.
* **High Prometheus memory usage** → too many metrics → use `metricRelabelings`.
* **Grafana no data** → check data source in Grafana.
* **Pods Pending** in monitoring namespace → check resource requests/limits.

---

#
