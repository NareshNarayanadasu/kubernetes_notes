
---

# **10-Week Advanced Kubernetes Daily Roadmap**

---

## **Week 1 – Kubernetes Deep Architecture & Core Concepts**

**Day 1–2: Cluster Architecture Deep Dive**

* Study:

  * Control plane components: kube-apiserver, kube-controller-manager, kube-scheduler
  * Node components: kubelet, kube-proxy, container runtime
  * etcd: architecture, backups
* Hands-on:

  * Inspect nodes and pods:

    ```bash
    kubectl get nodes -o wide
    kubectl get pods -A
    kubectl describe node <node-name>
    ```
  * Explore etcd data (for kubeadm cluster):

    ```bash
    ETCDCTL_API=3 etcdctl get / --prefix --keys-only
    ```

**Day 3–4: Pods, ReplicaSets, Deployments**

* Concepts:

  * Pod lifecycle, ReplicaSet, Deployments
  * Rolling updates, rollback, scaling
* Hands-on:

  * Create deployment:

    ```bash
    kubectl create deployment nginx --image=nginx
    kubectl scale deployment nginx --replicas=3
    kubectl rollout history deployment nginx
    kubectl rollout undo deployment nginx
    ```

**Day 5–6: StatefulSets & DaemonSets**

* Study differences between Deployment vs StatefulSet
* Hands-on:

  * Deploy StatefulSet with headless service:

    ```yaml
    apiVersion: apps/v1
    kind: StatefulSet
    ...
    ```
* Deploy DaemonSet:

  ```bash
  kubectl apply -f daemonset.yaml
  ```

**Day 7: Jobs & CronJobs**

* Create a job and a scheduled CronJob
* Test completion and logs:

  ```bash
  kubectl logs job/<job-name>
  kubectl get cronjobs
  ```

---

## **Week 2 – Networking in Kubernetes**

**Day 8–9: Pod Networking & CNI**

* Learn about ClusterIP, NodePort, LoadBalancer
* Hands-on: Install Calico or Flannel
* Test pod-to-pod connectivity:

  ```bash
  kubectl exec -it <pod> -- ping <other-pod-IP>
  ```

**Day 10–11: Services & Ingress**

* Hands-on:

  * Create ClusterIP, NodePort, LoadBalancer services
  * Deploy NGINX Ingress:

    ```bash
    kubectl apply -f ingress.yaml
    ```
  * Test routing using curl

**Day 12–13: DNS & Network Policies**

* Learn CoreDNS configuration and troubleshooting
* Hands-on:

  * Apply network policy to restrict traffic between pods

**Day 14: Networking Debug Lab**

* Simulate network issues and fix them:

  * Block pod-to-pod communication, observe effects
  * Check logs of CoreDNS pods
  * Test connectivity via `kubectl exec` and `nslookup`

---

## **Week 3 – Security & RBAC**

**Day 15–16: RBAC & Policies**

* Study Role, ClusterRole, RoleBinding, ClusterRoleBinding
* Hands-on:

  ```bash
  kubectl create role dev-role --verb=get,list,create --resource=pods
  kubectl create rolebinding dev-binding --role=dev-role --user=developer
  ```

**Day 17–18: Secrets & ConfigMaps**

* Encrypt secrets at rest
* Hands-on:

  ```bash
  kubectl create secret generic db-secret --from-literal=password=12345
  kubectl create configmap app-config --from-file=config.yaml
  ```

**Day 19–20: Pod Security & Image Scanning**

* Implement Pod Security Standards
* Scan container images using Trivy:

  ```bash
  trivy image nginx:latest
  ```

**Day 21: Security Lab**

* Apply network isolation via network policies
* Audit RBAC permissions
* Deploy a sample app with restricted access

---

## **Week 4 – Storage & Stateful Applications**

**Day 22–23: Volumes, PV & PVC**

* Hands-on:

  ```yaml
  apiVersion: v1
  kind: PersistentVolumeClaim
  ...
  ```
* Attach PVC to pod and verify storage persistence

**Day 24–25: StatefulSets with Databases**

* Deploy MySQL/Postgres StatefulSet
* Test persistent storage

**Day 26–27: StorageClasses & CSI**

* Learn dynamic provisioning
* Hands-on: Create StorageClass and dynamic PVC

**Day 28: Backup & DR Lab**

* Install Velero
* Backup and restore a namespace

---

## **Week 5 – Resource Management & Scheduling**

**Day 29–30: Resource Requests & Limits**

* Hands-on:

  ```yaml
  resources:
    requests:
      cpu: "100m"
      memory: "128Mi"
    limits:
      cpu: "500m"
      memory: "512Mi"
  ```

**Day 31–32: Affinity & Anti-Affinity**

* Deploy pods with node/pod affinity
* Test scheduling rules

**Day 33–34: Taints, Tolerations & Priority**

* Apply taints on nodes
* Schedule pods using tolerations
* Set priority classes and test preemption

**Day 35: Pod Disruption Budget Lab**

* Configure PDB for HA application
* Simulate node drain

---

## **Week 6 – Observability & Logging**

**Day 36–37: Metrics with Prometheus & Grafana**

* Install Prometheus
* Monitor pod metrics

**Day 38–39: Logging**

* Install EFK or Loki
* View logs centrally
* Tail logs for multi-container pods

**Day 40: Tracing**

* Deploy Jaeger or OpenTelemetry
* Trace request flow across microservices

**Day 41–42: Alerts**

* Configure Alertmanager
* Send alerts via Slack/Email on CPU/memory spikes

---

## **Week 7 – Deployment Strategies & CI/CD**

**Day 43–44: Helm & Kustomize**

* Deploy multi-service app with Helm
* Override values for dev/staging/prod

**Day 45–46: GitOps**

* Install ArgoCD or Flux
* Sync cluster with Git repo

**Day 47–48: Deployment Strategies**

* Rolling updates, Blue-Green, Canary
* Hands-on canary deployment lab

**Day 49: CI/CD Lab**

* Build full CI/CD pipeline: Git push → ArgoCD → Canary → Full rollout

---

## **Week 8 – Advanced Cluster Management**

**Day 50–51: Managed & Self-Hosted K8s**

* Learn EKS/GKE/AKS setup
* Hands-on: spin up test cluster with kubeadm

**Day 52–53: Autoscaling**

* Horizontal Pod Autoscaler (HPA)
* Vertical Pod Autoscaler (VPA)
* Cluster Autoscaler

**Day 54–55: Upgrades & Patching**

* Upgrade K8s version in test cluster
* Test backward compatibility

**Day 56: DR Lab**

* Simulate node failure
* Restore workloads with Velero

---

## **Week 9 – Extending Kubernetes**

**Day 57–58: CRDs**

* Create a custom resource
* Write a controller to manage CRD

**Day 59–60: Operators**

* Install and use a sample operator (e.g., etcd operator)
* Hands-on: automate DB backup using operator

**Day 61–62: API Aggregation & Webhooks**

* Study admission controllers
* Implement a validating webhook

**Day 63: Multi-Cluster Lab**

* Deploy workloads across two kind clusters
* Test cross-cluster service discovery

---

## **Week 10 – Production-Grade Practices & Real-World Projects**

**Day 64–65: High Availability**

* Deploy multi-replica control plane (if possible in lab)
* Configure HA applications with StatefulSets

**Day 66–67: Security & Compliance**

* Audit cluster with kube-bench or kube-hunter
* Enforce security policies

**Day 68–69: Observability & Troubleshooting**

* Simulate pod crash, node failure, network failure
* Troubleshoot with metrics, logs, and kubectl

**Day 70: Final Project**

* Deploy a full microservices application:

  * Frontend + backend + DB
  * Canary deployment + rollback
  * Monitoring, logging, alerting
  * Network policies & RBAC
  * Backup & restore test

---


