Here’s a **complete, in-depth guide for Day 52–53: Autoscaling in Kubernetes**, covering **concepts, architecture, hands-on examples, and best practices**. I’ve included **Horizontal Pod Autoscaler (HPA), Vertical Pod Autoscaler (VPA), and Cluster Autoscaler** in one structured document suitable for documentation or labs.

---

# **Day 52–53: Kubernetes Autoscaling**

---

## **1. Lab Objective**

* Learn **different types of autoscaling** in Kubernetes:

  1. Horizontal Pod Autoscaler (HPA) – scale pods horizontally
  2. Vertical Pod Autoscaler (VPA) – scale pod resources (CPU/memory)
  3. Cluster Autoscaler – scale nodes based on pod resource demands
* Implement autoscaling in a test cluster.
* Understand monitoring metrics, scaling triggers, and best practices.

---

## **2. Kubernetes Autoscaling Overview**

| Autoscaler         | Purpose                            | Scaling Type | Trigger                                    |
| ------------------ | ---------------------------------- | ------------ | ------------------------------------------ |
| HPA                | Scale number of pods               | Horizontal   | CPU/memory or custom metrics               |
| VPA                | Scale pod resource requests/limits | Vertical     | CPU/memory usage of pod                    |
| Cluster Autoscaler | Scale nodes in cluster             | Node-level   | Pending pods due to insufficient resources |

---

## **3. Horizontal Pod Autoscaler (HPA)**

### **3.1 Concept**

* HPA automatically increases/decreases the number of pod replicas based on:

  * CPU utilization
  * Memory usage (via Metrics API)
  * Custom metrics (Prometheus, external metrics)
* Example: scale NGINX pods between 2–10 replicas based on CPU usage.

### **3.2 Prerequisites**

* Metrics server installed:

```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

* Verify metrics server:

```bash
kubectl get deployment metrics-server -n kube-system
kubectl top nodes
kubectl top pods
```

### **3.3 Create HPA**

1. Deploy sample app:

```bash
kubectl create deployment nginx --image=nginx
kubectl expose deployment nginx --port=80
```

2. Create HPA targeting CPU utilization:

```bash
kubectl autoscale deployment nginx --cpu-percent=50 --min=2 --max=5
```

3. View HPA:

```bash
kubectl get hpa
kubectl describe hpa nginx
```

4. Test scaling:

* Generate load to trigger scaling:

```bash
kubectl run -i --tty load-generator --image=busybox --restart=Never -- /bin/sh
# Inside pod
while true; do wget -q -O- http://nginx; done
```

* Observe pod replicas scaling up:

```bash
kubectl get pods -w
```

---

## **4. Vertical Pod Autoscaler (VPA)**

### **4.1 Concept**

* VPA automatically adjusts **CPU and memory requests/limits** for pods.
* Useful for workloads with unpredictable resource usage.
* VPA **does not scale pod count** — only adjusts resources.

### **4.2 Install VPA**

```bash
kubectl apply -f https://github.com/kubernetes/autoscaler/releases/latest/download/vertical-pod-autoscaler.yaml
```

### **4.3 Create VPA Object**

```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: nginx-vpa
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind:       Deployment
    name:       nginx
  updatePolicy:
    updateMode: "Auto"
```

```bash
kubectl apply -f nginx-vpa.yaml
kubectl describe vpa nginx-vpa
```

* VPA monitors pods and adjusts CPU/memory requests automatically.

### **4.4 Notes**

* Avoid using HPA and VPA simultaneously on the same pod without careful configuration.
* Use `updateMode: Auto` for automatic resource adjustments or `Off` for recommendations only.

---

## **5. Cluster Autoscaler**

### **5.1 Concept**

* Automatically scales **cluster nodes** up or down based on pod demands.
* Works with cloud-managed clusters: EKS, GKE, AKS.
* Also works with self-hosted clusters if nodes are provisioned dynamically (cloud or VM auto-provisioning).

### **5.2 Features**

* Adds nodes when pods cannot be scheduled due to insufficient resources.
* Removes underutilized nodes to save cost.
* Works with multiple node groups or availability zones.

### **5.3 Deploy Cluster Autoscaler (EKS example)**

```bash
kubectl apply -f https://raw.githubusercontent.com/kubernetes/autoscaler/cluster-autoscaler/master/examples/cluster-autoscaler-one-asg.yaml
```

* Annotate deployment:

```bash
kubectl -n kube-system annotate deployment cluster-autoscaler \
  cluster-autoscaler.kubernetes.io/safe-to-evict="true"
```

* Configure autoscaler for min/max nodes and node groups in cloud provider settings.

---

## **6. Testing Autoscaling in Lab**

### **Step 1: Test HPA**

1. Deploy CPU-intensive workload:

```bash
kubectl run stress --image=alpine --limits="cpu=200m" --requests="cpu=100m" -- /bin/sh -c "while true; do :; done"
```

2. Watch HPA scale pods up/down:

```bash
kubectl get hpa -w
```

### **Step 2: Test VPA**

1. Observe recommended CPU/memory:

```bash
kubectl get vpa
kubectl describe vpa nginx-vpa
```

2. Adjust resources automatically.

### **Step 3: Test Cluster Autoscaler**

1. Deploy pods exceeding node capacity.
2. Observe new nodes provisioned automatically (cloud) or trigger scaling events in self-hosted cluster.

---

## **7. Best Practices**

* HPA:

  * Set **CPU/memory thresholds** realistically.
  * Use **custom metrics** for non-CPU workloads.
* VPA:

  * Avoid conflicts with HPA.
  * Use VPA for workloads with unpredictable memory/CPU usage.
* Cluster Autoscaler:

  * Set min/max nodes per node group.
  * Enable **safe-to-evict** annotation for pods.
  * Monitor scaling events for cost optimization.
* Always monitor scaling behavior in **Grafana/Prometheus**.

---

## **8. Troubleshooting**

| Issue                               | Solution                                                 |
| ----------------------------------- | -------------------------------------------------------- |
| HPA not scaling                     | Check metrics-server installed & running                 |
| HPA reports “unknown metrics”       | Verify `kubectl top pods` works                          |
| VPA not updating pods               | Ensure `updateMode: Auto`                                |
| Cluster autoscaler not adding nodes | Check node group configuration and pod scheduling events |

---

## **9. Lab Summary**

1. Understand types of autoscaling in Kubernetes: **HPA, VPA, Cluster Autoscaler**.
2. Install metrics-server and VPA components.
3. Deploy HPA on sample workload and test CPU-based scaling.
4. Deploy VPA and observe resource adjustments.
5. Deploy Cluster Autoscaler and simulate node scaling.
6. Learn best practices and monitor autoscaling behavior.

✅ **Outcome:**

* Hands-on experience with all three types of Kubernetes autoscaling.
* Ability to scale pods and clusters automatically based on real workload demands.
* Prepared to implement autoscaling in production environments.

---


